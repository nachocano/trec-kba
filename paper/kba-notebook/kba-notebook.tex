\documentclass{article}
%\usepackage{icml2014} 
\usepackage[accepted]{icml2014}
\usepackage{times}
\usepackage{graphicx}
%\usepackage{mdwlist}
\usepackage{bbm}
\usepackage{microtype}
\usepackage{color}
\usepackage{natbib}
%\usepackage{todonotes}
\usepackage{algorithm}
\usepackage{algorithmic}
\usepackage{multirow}
\usepackage{hyperref}
\usepackage{booktabs}

\newcommand{\theHalgorithm}{\arabic{algorithm}}
\newcommand{\todo}[1]{\noindent{\textcolor{red}{\{{\bf TODO:}  #1\}}}}

\usepackage{subcaption}

\usepackage{amsmath}
\DeclareMathOperator*{\argmin}{arg\,min}


\icmltitlerunning{Distributed Non-Parametric Representations for Vital Filtering}

\begin{document} 

\twocolumn[
\icmltitle{Distributed Non-Parametric Representations for Vital Filtering:\\UW at TREC KBA 2014}

\icmlauthor{Ignacio Cano}{icano@cs.washington.edu}
%\icmladdress{University of Washington, P. Allen Center, 185 Stevens Way, Seattle, WA 98195 USA}
\icmlauthor{Sameer Singh}{sameer@cs.washington.edu}
%\icmladdress{University of Washington, P. Allen Center, 185 Stevens Way, Seattle, WA 98195 USA}
\icmlauthor{Carlos Guestrin}{guestrin@cs.washington.edu}
\icmladdress{Computer Science and Engineering, University of Washington, Seattle, WA 98195 USA}

\icmlkeywords{non-parametric clustering, nlp, word embeddings, vital filtering, streaming}

\vskip 0.3in
]

\begin{abstract} 

To efficiently explore large corpora of text documents, we need to identify references to entities of interest as well as studying their topics evolve over time. Existing approaches are limited; they are unable to handle streaming data, do not partition entities' references according to topics, or do not accurately estimate temporal vitalness.
In this paper we introduce a distributed, non-parametric representation of documents that addresses the above limitations. To efficiently handle lexical sparsity, we propose using word embedding representation of the contexts. Each entity context is described by topic clusters that are estimated in a non-parametric manner. Further, we associate a staleness measure to each entity and topic cluster, dynamically estimating their temporal relevance. % based on document frequencies.
This approach of using distributed word embeddings, non-parametric clustering, and staleness, provides an efficient and appropriate representation of entities' contexts for the streaming setting, facilitating accurate vital filtering.


\end{abstract} 

\section{Introduction}
\label{intro}

\citet{frank12} observe a considerable time lag between the publication date of cited articles and the date of the corresponding citations created in Wikipedia. The median time is over a year, and the distribution has a long and heavy tail. This gap could be drastically reduced if automatic systems could suggest relevant documents to editors as soon as they are published.

However, when processing a large corpus of text documents, practitioners are often concerned in finding references to entities of interest \cite{RaoMD10, choi2007}, and studying their topics distributions over time \cite{blei12}. Current tools are somewhat limited; they do not handle online settings, and they do not cluster entities' references according to topics nor identify the references' importance.

Recent studies \cite{xitong13, bouvier13, efron13, zhang13, bellogin13} have centered their attention on solving the above problems with supervised methods, using mainly document, document-entity and temporal level features. \citet{Turian10wordrepresentations} showed that by using unlabeled examples to reduce data sparsity in the labeled training data, semi-supervised approaches can improve the generalization accuracy of those supervised systems.

We therefore introduce a semi-supervised approach suitable for streaming settings that uses a distributed word embedding and a non-parametric topic cluster representation of entities' contexts. We also include a staleness measure that approximates the relevance of each entity and its topic clusters according to document frequencies. Further, we update the topic identities, number of topics, and the entities and topics staleness in an online fashion, observing only a single document at a time.

This combination of distributed word embeddings, non-parametric clustering, and staleness measure provides an efficient yet accurate representation of entities' contexts that can be updated in a streaming manner, thus addressing the document filtering requirements on large streams of text.

We present experimental results demonstrating the benefits of our method and show that it surpasses previous supervised approaches in TRECKBA14 Vital Filtering task.

\section{Background}
\label{background}

\subsection{Problem Setup}
\label{setup}

We assume a set of $m$ target entities $E = \left\{ {e_1, ..., e_m}\right\}$. We further assume a set of $n$ documents $D = \left\{ {d_{1}, ..., d_{n}}\right\}$ that arrive in chronological order. 
 
Each document is a sequence of sentences composed by collections of words, annotated with NLP tools.
Further, we assume w.l.o.g. that every document in $D$ refers to a single entity $e \in E$. For illustrative purposes we let $e\mathord{=}Barack\hspace{1mm}Obama$.

We represent each $d_i \in D$ as a compound of a timestamp $t_i$ and a set of $p$ words $W_i = \left\{ {w_{i1}, ..., w_{ip}}\right\}$ located around (and including) mentions to the entity $e$. A mention to $e$ is found by a string matching algorithm that searches for exact matches of canonical and surface form names of the entity $e$.

We assume an online setting, i.e. the algorithm should provide predictions for documents arriving at time $t$ before seeing documents arriving at time $t+1$.

Further, documents can be categorized as follows:

\begin{itemize}
    \item $Vital$: the document contains information that at the time it enters the stream, it drives an update to the entity $e$ with timely, new information about the entity's current state, actions or situation, e.g. ``Barack Obama has been elected President''.
    \item $Non\mathord{-}Vital$: the document contains information that can be used when building an initial profile of the entity $e$, it means that the document is possibly citable but the information is not timely, e.g. ``Barack Obama was born on August 4th, 1961''.
\end{itemize}

\subsection{Word Embeddings}
\label{emb}

A word embedding is a dense, low-dimensional, and real-valued vector associated with a word. Each dimension of the embedding represents a latent feature of the word, and hopefully captures useful syntactic and semantic properties \cite{Turian10wordrepresentations}.

The learned vectors computed using neural networks are very attractive because they explicitly encode many linguistic regularities and patterns. Many of these patterns can be represented with simple algebraic operations. For example, the result of $v_{paris} - v_{france} + v_{germany}$ is closer to $v_{berlin}$ than to any other word vector \cite{mikolovChen,mikolovYih}.

Given the recent fast estimation of embedding representations at very large scale, there is rising interest in vector-space word embeddings and their use in NLP \cite{Arvind14}.

\section{Approach}
\label{approach}
\todo{better name for section. Used approach instead of method, maybe you have something else on your mind}
Given a stream of documents $D$ that refer to entity $e$, the task at hand is to predict whether those documents are $vital$ or $non\mathord{-}vital$ to $e$. For this, we propose a three-step method: 1) represent documents with embeddings computed from sets of words in each document, 2) represent the entity's context using non-parametric topic clusters, and 3) estimate the novelty of the document information with respect to entity $e$ using a staleness measure.

In section \ref{docwordemb} we describe the way to determine the word embedding representation of a document given the set of words located close to mentions of entity $e$. In section \ref{non}, we introduce the non-parametric representation of the entity's context. Finally, in section \ref{staleness} we present the staleness measure, which is a good indicator of the novelty of the information contained in a document with respect to $e$.

\subsection{Context Embedding Representation of Documents}
\label{docwordemb}

\todo{better structure in paras: problem, solutions, why they aren't enough, our solution.. added BOW, moved the topic models to next subsection, first sentence doesn't sound good enough}

We need to represent the unstructured entity's contexts in documents as features for our classifier. A common solution to this problem is using Bag of Words (BOW) models, where a document is represented as the bag of its words, disregarding grammar and even word order. This type of models are generally sparse.

In order to address the lexical sparsity, given the nice properties exposed in section \ref{emb}, we propose to represent entity's contexts in documents by their mean word embedding vector.

We define a function $f : w \rightarrow v_w \in \mathbf{R^d}$ that computes the word embedding representation of the word string $w$. We further define a function $g : W \rightarrow v_W \in \mathbf{R^d}$ that computes the mean word embedding representation of the set of words in $W$ as defined in Equation \ref{wordembedding}.
\begin{equation}
\label{wordembedding}
g(W) = v_W = \frac{1}{|W|} \sum_{w \in W}{f(w)}
\end{equation}
Given the document $d_i \in D$ that refers to entity $e$ and contains the words $w_i \in W_i$, we can compute its vector representation using function $g$ as follows:
\begin{equation}
\label{wordembedding1}
v_{d_i} = v_{W_i} = g(W_i)
\end{equation}
With this, we intend to capture the context where the entity $e$ is mentioned in a document, i.e. the topic, and represent it with a dense, low-dimensional vector.

Further, let's denote $W_{i_n}$ to the set of all nouns in $W_i$, where $W_{i_n} \subseteq W_i$, and $W_{i_v}$ to the set of all verbs in $W_i$, where $W_{i_v} \subseteq W_i$. We can simply compute the mean embedding vector of all the nouns and verbs that appear in the context of entity $e$ using function $g$, as shown below:
\begin{eqnarray}
v_{d_{i_n}} = v_{W_{i_n}} = g(W_{i_n})\label{nouns}
\\
v_{d_{i_v}} = v_{W_{i_v}} = g(W_{i_v})\label{verbs}
\end{eqnarray}
Being able to compute individual embeddings for different word types is a flexibility our method provides that might better encapsulate the truth underlying context (topic) of the document.

\subsection{Non-parametric Clustering}
\label{non}

\todo{better structure in paras: problem, solutions, why they aren't enough, our solution. Put something on topic models, take a look}

We further want to uncover the hidden thematic structure of each entity reference in the stream of documents. One typical approach to tackle this problem is by using topic models. This type of models represent documents as admixtures over topics. More specifically, each topic is modeled as a distribution over words, and each document is a mixture of such topics \cite{InouyeRD14}. Though they can be easily extended and embedded in other models, they do not generalize to new, unseen documents and they are prone to overfitting. Furthermore, they are expensive to compute and do not easily fit into the streaming setting.

To address these limitations and be able to generalize to unseen documents, we propose to represent the context of entity $e$ by topic clusters. Each cluster is estimated in a non-parametric manner by assuming that the entity's context in a single document belongs to a single topic. As we are dealing with a streaming setting, topic clusters do evolve over time, i.e. members of each cluster change over time. We therefore represent each topic cluster by the mean embedding vector of the documents in that cluster at a certain timestamp.

Mathematically, the vector representation of the $j$-th topic cluster at timestamp $t_i$, $c^j_i$, can be computed using Equation \ref{nonparamclust}.
\begin{equation}
\label{nonparamclust}
v_{c^j_i} = \frac{1}{|D^j_i|} \sum_{d \in D^j_i}{v_d}
\end{equation}
where $D^j_i$ is the subset of all the documents that belong to cluster $j$ at timestamp $t_i$, and $\forall\hspace{1mm}d_q \in D^j_i, t_q \leq t_i$.

The number of topic clusters for the context of entity $e$ is unknown beforehand. Initially, the entity's context does not have topic clusters. We create the first topic cluster for the entity's context on its first occurrence in the training data. After creating the first cluster for the context, a new topic cluster is created when the cosine distance between the word embedding representation of the new arriving document with every topic cluster center of the entity is greater than or equal to $\alpha$, where $\alpha$ is an hyperparameter of the model, and $0 \leq \alpha \leq 1$. Our approach is closely related to the online non-parametric clustering procedure described in \citet{Arvind14}.

In case the distance is less than $\alpha$, we add the incoming document to the closest topic cluster and update its center. 

More formally, $\forall\hspace{1mm}c^j_{i-1}$, at time $i$, document $d_i$ is added to the topic cluster that solves the following optimization problem:
\begin{eqnarray}
\underset{j}{\argmin}\;\; dist(v_{d_i}, v_{c^j_{i-1}}) \nonumber\\
\text{subject to}~dist(v_{d_i}, v_{c^j_{i-1}}) < \alpha 
\end{eqnarray}
where $dist(\cdot,\cdot)$ is the cosine distance defined as: %in Equation \ref{cosine}.
\begin{equation}
\label{cosine}
dist(x,y) = 1 - \cos(x,y) = 1 - \frac{x \cdot y}{||x||||y||}
\end{equation}
The $j$-th topic cluster at time $i$ is updated, and therefore composed by the subset of documents $D^j_i \subseteq D$, where $D^j_i = D^j_{i-1} \cup \left\{ {d_i}\right\}$.

%\begin{algorithm}[tb]
%   \caption{Non-parametric Clustering}
%   \label{nonparamclustering}
%\begin{algorithmic}
%   \STATE {\bfseries Input:} $doc=doc\_word\_embedding(d, e, c)$, and topic clusters list $tcs$ for entity $e$
%   \STATE {\bfseries Output:} new or updated topic cluster $tc$
%   \STATE {\bfseries Body:}
%   \STATE Initialize $tc = nil$
%   \IF{$tcs$ {\bfseries is empty}}
%    \STATE $tc = create\_topic\_cluster(center\mathord{=}doc)$
%    \STATE $tcs.append(tc)$
%   \ELSE
%     \STATE $dist, i \mathord{=} \min_{\forall{i \in tcs}}{cosine\_dist(tcs[i].center, doc)}$
%     \IF{$dist >= \alpha$ }
%        \STATE $tc = create\_topic\_cluster(center\mathord{=}doc)$
%        \STATE $tcs.append(tc)$
%     \ELSE
%        \STATE $tc = update\_topic\_cluster(tcs[i], doc)$
%     \ENDIF
%   \ENDIF
%   \STATE return $tc$
%\end{algorithmic}
%\end{algorithm}

As an example, let's assume document $d_1$ appears in the stream, and talks about the days Barack Obama was a Senator. As is the first document referring to the entity Obama, we add $d_1$ to a new topic cluster $senator$. Then, document $d_2$ appears in the stream. It refers to Obama as being elected President of the United States. The distance with the previous cluster $senator$ is greater than $\alpha$, therefore the algorithm proceeds to add $d_2$ to a new topic cluster $president$. Finally, $d_3$ enters the stream. It talks about Obama as the current President of the U.S. The algorithm compares its distance to the previous clusters and finds that is closest to the $president$ cluster. The distance is less than $\alpha$, hence it adds $d_3$ to the $president$ cluster and updates the cluster center. 

Figure \ref{obama} illustrates the aforementioned example, assuming that each document is represented in a two-dimensional vector.

\begin{figure}[tb]
\centering
\includegraphics[width=0.7\columnwidth]{fig/obamaExample.pdf}
\caption{Non-parametric Clustering example for entity Obama}
\label{obama}
\end{figure}

\subsection{Staleness}
\label{staleness}

\todo{better structure in paras: problem, solutions, why they aren't enough, our solution. Put something on the timeliness stuff, not sure which are other
solutions to this}

As mentioned in section \ref{setup}, the notion of $vitalness$ is closely related to the timeliness of the new information. The timeliness is a subjective interpretation that can vary per entity and event. As an example let's assume that several documents talk about an event that happened to entity $e$. During a ``short'' timeframe (here is where the subjective interpretation comes in) that information can be considered new. After a while, that new information transitions to a background state, so as the documents transition from being $vital$ to $non\mathord{-}vital$.

In order to capture this temporal dynamics that involve a transition from a $vital$ to a $non\mathord{-}vital$ state, we propose a staleness feature $\lambda_i$, which is dynamically updated over time, and $0 < \lambda_i \leq 1$. Low staleness aims to represent $vital$ documents, while high staleness intend to represent $non\mathord{-}vital$ ones.

This staleness measure can be used both for entities and topic clusters.

The staleness update is a two-step process, an exponential decrease followed by a constant increase.
We denote the staleness decrease as $\lambda^{dec}_i$, and is controlled by the hyperparameter $\gamma_d$ following an exponential decay model.
\begin{equation}
\label{decrease}
\lambda^{dec}_i = \lambda^{inc}_{{i-1}} \exp{(-\gamma_d \frac{t_i-t_{i-1}}{T})}
\end{equation}
where $\gamma_d \geq 0$, $t_i$ is the $i$-th document timestamp, $t_{i-1}$ is the $i-1$ document timestamp, $T$ is a normalizing constant, and $\lambda^{inc}_{i-1}$ is the staleness increase (defined below) at a previous timestamp.
In case we use staleness as an entity's measure, $\lambda^{inc}_{i-1}$ alludes to the staleness of the previous document in the stream that refers to the same entity as document $i$.
If we use staleness as a topic cluster's measure, $\lambda^{inc}_{i-1}$ refers to the staleness of the previous document that belongs to the same topic cluster as document $i$.

On the other hand, the staleness increase is denoted as $\lambda^{inc}_i$, and is regulated by $\gamma_i$ according to the following expression
\begin{equation}
\lambda^{inc}_i = 1 - (1 - \lambda^{dec}_i) \gamma_i
\end{equation}
where $0 \leq \gamma_i \leq 1$.

The final staleness feature reported for the $i$-th document is $\lambda^{dec}_i$.

\subsubsection{Examples}

Figures \ref{stalenesslow} and \ref{stalenessmedium} illustrate some toy examples to further understand the intuition behind staleness.

Figure \ref{stalenesslow} intends to show an example of an entity with a decreasing staleness. There are almost no documents in the stream referred to that entity. As soon as some activity is detected, i.e. a document mentioning the entity appears ($t\mathord{=}10$), a slight increase in the curve is seen. Given the fact that there's no much information about the entity, every new document would drive an update to the entity's profile, strongly suggesting vitalness.

\begin{figure}[tb]
\centering
\includegraphics[width=0.7\columnwidth]{fig/staleness1.pdf}
\caption{Staleness of Unpopular Entity}
\label{stalenesslow}
\end{figure}

Figure \ref{stalenessmedium} aims to represent staleness of an entity with fluctuating activity levels in the stream of documents. At time $t\mathord{=}10$, a main event involving the entity starts and continues for a long period of time, showing a growing trend in popularity. 
At the beginning, those documents can be considered vital, but as time goes by and documents continue commenting on the same event, the information starts staling, clearly indicating non-vitalness.
Near $t\mathord{=}40$, the event can be considered over, a steep decrease in popularity is shown. At a later time, $t=50$, a new event occurs, which denotes vitalness.

\begin{figure}[tb]
\centering
\includegraphics[width=0.7\columnwidth]{fig/staleness2.pdf}
\caption{Staleness of Entity with Fluctuating Popularity}
\label{stalenessmedium}
\end{figure}

\section{Visualization for Accelerate and Create}

%There is an urgent need for efficient analysis of constantly increasing text collections.
Visualization techniques provide natural and effective ways to analyze large collections of documents. In this section, we present our data visualization prototype for the Accelerate \& Create task, suitable for streaming corpora of text documents, that enables the user to enlarge a certain part of the visual space while simultaneously shrinking the context, a technique called focus-plus-context \cite{Artur2010}.

\subsection{Goals and Challenges}

Visual exploration of text streams is a challenging task. As text streams continuously evolve, visualization methods should allow 
to trace the temporal evolution of existing topics, detect new ones, and examine the relationships between them. Such systems should also allow 
users to interactively change the information they are seeking at any time. Interactivity is therefore a crucial factor in a domain where users
do not know the text documents in advance \cite{AlsakranCLZYDL12}.

In this work we intend to provide an easy-to-use vizualization that enables users debug what is going on in the sytem. We provide different mechanisms to select data based on users interests; in particular we focus our attention on providing interactive time-series widgets.

\subsection{Our Solution}

We propose a browser-based visualization prototype that enables users to switch between multiple entities of interest, select the time ranges to explore over, explore the prominence of topics over time, and understand the topics using lists of similar words.

%\begin{figure}[tb]
%\centering
%\end{figure}

Figure \ref{vitalEvol} illustrates the distribution of predictions of entity Kshama Sawant in a specific period of time. The entity search box has been omitted for space reasons.

Figure \ref{stalenessEvol} shows the staleness evolution for the different topic clusters of entity Mike Kluse. The user can select any point in the line to further inspect the topic cluster. Figure \ref{wordcloud} is the result of a user click on the point highlighted in Figure \ref{stalenessEvol}. It shows the closest words to the cluster C1 centroid at that time.

Both charts contain an active (zoomed) section which can be changed using the time range filters located below. Legends can also act as filters, users have the possibility to observe particular clusters or predictions by selecting them in the legend region.

With these interactive time-series controls plus word cloud representations, we provide a system that allow users to explore streaming text data and filter information based on their needs.

\begin{figure}[tb]
        \centering
        \begin{subfigure}[b]{0.4\textwidth}
			\includegraphics[width=\textwidth]{fig/vitalDistribution.png}
			\caption{Predictions Distribution chart example}
			\label{vitalEvol}
        \end{subfigure}
        \\
        \begin{subfigure}[b]{0.4\textwidth}
            \includegraphics[width=\textwidth]{fig/stalenessDistribution.png}
			\caption{Staleness chart example}
			\label{stalenessEvol}
        \end{subfigure}
        \\
        \begin{subfigure}[b]{0.25\textwidth}
    		\raisebox{0mm}{\includegraphics[width=\textwidth]{fig/wordclouds.png}}
			\caption{Topic cluster example}
			\label{wordcloud}
        \end{subfigure}
        \caption{Staleness and Topic cluster evolution}
\end{figure}

\section{Related Work}
\label{related}

Streaming document filtering is related to several fields, including but not limited to, entity linking \cite{KBP11}, text categorization \cite{HLTCOE12}, news surveillance \cite{Steinberger14}.

Several comparative knowledge based population competitions have run in the recent past testifying on the great progress achieved in these fields \cite{gross_doucet_toivonen_trec12}. 

\citet{xitong12} presented one of the best performing systems in TRECKBA12. They created wider representations of entities' profiles based on a Wikipedia snapshot and considered the anchor text of all internal Wikipedia links as related entities. In TRECKBA13 competition, different families of methods were proposed, query expansion, classification, learning to rank. 

Our strategy is somewhat similar to \citet{jingang13} in the sense that we first target for a high recall system and then apply different classification methods to differentiate between $vital$ and $non\mathord{-}vital$ documents. Nevertheless, one key difference is that we do not exploit any external resources to construct features, e.g. we do not use Wikipedia entity pages nor existing citations in the Wikipedia page of an entity. 

Representing words as continuous vectors has been around for a while \cite{Hinton87, Elman90findingstructure}. The progress of machine learning techniques in recent years enabled training more complex models on much larger data sets \cite{mikolovChen}. One popular approach to increase accuracy in existing system is to use unsupervised methods to create word features, or to download word features that have already been produced \cite{Turian10wordrepresentations}. In our method, we do the latter, we use already induced word embedding features in order to improve its accuracy.

To our best knowledge, no recent techniques propose a combination of distributed word embeddings, non-parametric clustering and a staleness notion to solve this problem. 

The closest example we found that addresses the problem of staleness detection is \citet{gamon}, where he builds an association graph connecting sentences and sentence fragments, and uses some graph-based features as good indicators of lack of novelty.

\section{KBA Vital Filtering Evaluation}
\label{evaluation}

\subsection{Data}
\label{data}

To assess our method we use TRECKBA14 stream corpus. It has around 20M documents annotated with BBN's Serif NLP tools, including within-doc coref and dependency parse trees. Further, we use the 71 target entities given by TRECKBA14 organizers for the Vital Filtering task. Among the 20M documents, around 28K have truth labels. From these, only 8K are training instances while the rest are test examples.

\subsubsection{Preprocess}

We preprocess the corpus to filter the documents that contain exact string matches to the target entities names, including canonical and surface form names.

\subsubsection{Categories}
\label{subcat}

TRECKBA14 corpus contain documents that do not refer to the target entities, even though they may contain mentions to them. We therefore need to introduce a new category of documents, \emph{non-referent}. 

A \emph{non-referent} document means that it doesn't refer to a target entity or the context is so ambiguous that is impossible to decide whether the mention refers to an entity or not. An example for the former case is ``Barack Ferrazzano provides a wide range of business-oriented legal''. For the latter, an example is ``Barack is a great father and a better husband''. The mention ``Barack'' may refer to any married parent named Barack, therefore, we consider it \emph{non-referent}.

The \emph{vital} and \emph{non-vital} classes described in section \ref{setup} fall into a \emph{relevant} category, which contains documents that refer to the target entities.

\subsection{Features}
\label{feat}

\todo{uncomment features table and fix position, don't know how to do it properly}
A summary of the features we use is presented in Table \ref{features}. Basic features are borrowed from \cite{jingang13}.

%\comment{

\begin{table}[tb]
\center
{\small
\begin{tabular}{p{0.2\columnwidth}p{0.73\columnwidth}}
\toprule
%\textbf{FEATURE} & \textbf{DESCRIPTION} \\ 
\multicolumn{2}{c}{\textbf{Basic Features, $F_b$}} \\ %\hline
\midrule
\multicolumn{2}{l}{\emph{Based on document $d$}} \\ %\hline
$\log(len(d))$ & log of the length of $d$ \\ %\hline
$source(d)$ & discretized source of $d$ \\
\multicolumn{2}{l}{\emph{Based on document $d$ and target entity $e$}} \\ %\hline
$n(d,e)$ & \# of occurrences of target entity $e$ in $d$ \\
$n(d,e^p)$ & \# of occurrences of partial name of $e$ in $d$ \\
$\text{fpos}(d,e)$ & position of first occurrence of entity $e$ in $d$ \\
$\text{fpos}_n(d,e)$ & $\text{fpos}(d,e)$ normalized by document length \\
$\text{fpos}(d,e^p)$ & position of first partial occurrence of $e$ in $d$ \\
$\text{fpos}_n(d,e^p)$ & $\text{fpos}(d,e_p)$ normalized by document length \\
$\text{lpos}(d,e)$ & position of last occurrence of entity $e$ in $d$ \\
$\text{lpos}_n(d,e)$ & $\text{lpos}(d,e)$ normalized by document length \\
$\text{lpos}(d,e^p)$ & position of last partial occurrence of entity $e$ in $d$ \\
$\text{lpos}_n(d,e^p)$ & $\text{lpos}(d,e^p)$ normalized by document length \\ 
$\text{spread}(d,e)$ & $\text{lpos}(d,e) - \text{fpos}(d,e)$ \\
$\text{spread}_n(d,e)$ & $\text{spread}(d,e)$ normalized by document length \\
$\text{spread}(d,e^p)$ & $\text{lpos}(d,e^p)\mathord{-}\text{fpos}(d,e^p)$ \\
$\text{spread}_n(d,e^p)$ & $\text{spread}(d,e^p)$ normalized by document length \\ 
\midrule
\multicolumn{2}{c}{\textbf{Embedding Features, $F_e$}} \\ %\hline
\midrule
  $v_d$ & mean word embedding representation of $d$ \\
  $\text{zero}(v_d)$& $\mathbbm{1}_{v_d=0}$, set to 1 if $v_d$ is $0$ \\
\midrule
\multicolumn{2}{c}{\textbf{Clustering Features, $F_c$}} \\ %\hline
\midrule
  $\min_c(v_d,v_c)$& minimum distance of $v_d$ to topic clusters of $e$ \\
  $\text{avg}_c(v_d,v_c)$& average distance of $v_d$ to topic clusters of $e$ \\
\midrule
\multicolumn{2}{c}{\textbf{Temporal Features, $F_t$}} \\ %\hline
\midrule
  $\lambda(e)$& current staleness of entity $e$ \\
  $\lambda(e,c)$& current staleness of topic $c$ of target entity $e$ \\
\bottomrule
\end{tabular}
} % end of small
\caption{\todo{add better caption}Features}
\label{features}
\end{table}

%} %end comment

\subsection{Methods}
\label{expe}

Due to the fact that not all documents in the corpus refer to the target entities (section \ref{subcat}), we include an extra step in our classification process. We introduce an additional classifier, called $rnr$, which acts offline and classifies documents as \emph{referent} or \emph{non-referent}.

Consequently, in every experiment, each document goes first through the \emph{rnr} classifier. Only the \emph{relevant} documents outputted by \emph{rnr} are used as inputs to the $uv$ model, which discriminates between $vital$ and $non\mathord{-}vital$ documents, the overall focus of this work.

We use therefore two extremely randomized tree ensembles classifiers \cite{GEW06a} in cascade, each composed of 100 weak learners. Each tree in the ensembles has depth 150.

All the experiments use the same \emph{rnr} model trained with the basic features listed in section \ref{feat}. 
The different models differ on the features used to train and test the $uv$ classifier.

\begin{itemize}
  \item {\textit{Baseline Single}}: baseline method that uses basic document and document-entity features. \citet{jingang13, bellogin13} have a similar method, though they train their models with more features.
  \item {\textit{Baseline Multi-task}}: another baseline method. It's similar to {\textit{Basic Single}} but it includes multi-task learning \cite{Caruana93multitasklearning}.
  \item {\textit{Embedding Combined}}: similar to {\textit{Basic Multi-task}}. It also includes the embeddings features. The word embeddings are computed using the pre-trained Google News dataset. Each document has a single combined embedding, which is calculated from the nouns, proper nouns and verbs found near the mentions to entities as explained in section \ref{docwordemb}.
  \item {\textit{Embedding POS}}: similar to {\textit{Embedding Combined}} but instead of a single combined embedding per document, it has one embedding per word type in each document, i.e. it computes separate embeddings for nouns, proper nouns and verbs. It uses the part of speech annotations in the documents to easily extract the different word types.
  \item {\textit{Mean Static}}: similar to {\textit{Embedding POS}}. It also includes the staleness measure, which is constant throughout the stream, as $\gamma_d = 0$ and $\gamma_i = 1$. No topic clusters are formed, this means that $\alpha = 1$.
  \item {\textit{Mean Dynamic}}: similar to {\textit{Embedding POS}}. Further, it includes the staleness measure, which fluctuates over time as $\gamma_d \neq 0$ and $\gamma_i \neq 1$. Still no topic clusters are formed, i.e. $\alpha = 1$.
  \item {\textit{Clustering Static}}: similar to {\textit{Mean Static}} in the sense that the staleness is constant over time, i.e. $\gamma_d = 0$ and $\gamma_i = 1$, but it also includes topic clusters by making $\alpha \neq 1$.
  \item {\textit{Clustering Dynamic}}: similar to {\textit{Mean Dynamic}} in the sense that the staleness fluctuates over time, i.e. $\gamma_d \neq 0$ and $\gamma_i \neq 1$, but it also adds topic clusters by making $\alpha \neq 1$.
\end{itemize}

\section{Results and Discussion}

\todo{Results of the RNR classification, of all the different approaches, see Table \ref{resMacro}}

Table \ref{resMacro} shows the macro precision, recall and F1 results of the methods explained in \ref{expe}, computed using KBA official scorer tool with cutoff=50. The \textit{Clustering} models use $\alpha=0.8$. Also, the \textit{Dynamic} methods use $\gamma_d=1$ and $\gamma_i=0.1$.

% MICRO
%\begin{table}[H]
%\center
%\begin{tabular}{|c|c|c|c|c|} \hline
%\textbf{Model} & \textbf{P} & \textbf{R} & \textbf{F1} \\ \hline\hline
%{\textit{Baseline Single}} & 0.538 & 0.265 & 0.355 \\ \hline
%{\textit{Baseline Multi-task}} & \textbf{0.607} & 0.414 & 0.492 \\ \hline
%{\textit{Embedding Combined}} & 0.547 & \textbf{0.521} & \textbf{0.534} \\ \hline
%{\textit{Embedding POS}} & 0.538 & 0.464 & 0.498 \\ \hline
%{\textit{Mean Static}} & 0.573 & 0.476 & 0.520 \\ \hline
%{\textit{Mean Dynamic}} & 0.572 & 0.482 & 0.524 \\ \hline
%{\textit{Clustering Static}} & 0.569 & 0.490 & 0.527 \\ \hline
%{\textit{Clustering Dynamic}} & 0.562 & 0.481 & 0.518 \\ \hline
%\end{tabular}
%\caption{TRECKBA14 Vital Filtering scores}
%\label{resMicro}
%\end{table}

%MACRO
\begin{table*}[tb]
{\small
\begin{center}
\begin{tabular}{llccccccccc} 
\toprule
  \multirow{2}{*}{\textbf{Model}} & 
  \multirow{2}{*}{\textbf{Features}} & 
  \multicolumn{3}{c}{\textbf{Useful}, \emph{macro}} & 
  \multicolumn{3}{c}{\textbf{Vital Filtering}, \emph{micro}} &
  \multicolumn{3}{c}{\textbf{Vital Filtering}, \emph{macro}}
\\ 
  \cmidrule(lr){3-5}
  \cmidrule(lr){6-8}
  \cmidrule(lr){9-11}
&   & 
  \textbf{P} & \textbf{R} & \textbf{F1} & 
  \textbf{P} & \textbf{R} & \textbf{F1} & 
  \textbf{P} & \textbf{R} & \textbf{F1} \\ 
\midrule
{\textit{Baseline Single}} & $F_b$ &
	x & x & x & 
	x & x & x &
	 \textbf{0.476} & 0.238 & 0.317 \\
{\textit{Baseline Multi-task}} & $F_b$ &
	x & x & x & 
	x & x & x &
	0.367 & \textbf{0.405} & 0.385 \\
{\textit{Embedding Combined}} & $F_b+F_e$ & 
	x & x & x & 
	x & x & x &
	0.449 & 0.376 & \textbf{0.409} \\
{\textit{Embedding POS}} & $F_b+F_e$ & 
	x & x & x & 
	x & x & x &
	0.440 & 0.329 & 0.376 \\
{\textit{Mean Static}} & $F_b+F_e$ & 
	x & x & x & 
	x & x & x &
	0.461 & 0.334 & 0.388 \\
{\textit{Mean Dynamic}} & $F_b+F_e+F_t$ & 
	x & x & x & 
	x & x & x &
	0.475 & 0.338 & 0.395 \\
{\textit{Clustering Static}} & $F_b+F_e+F_c$ & 
	x & x & x & 
	x & x & x &
	0.464 & 0.342 & 0.394 \\
{\textit{Clustering Dynamic}} & $F_b+F_e+F_c+F_t$ & 
	x & x & x & 
	x & x & x &
	0.461 & 0.326 & 0.382 \\ 
\bottomrule
\end{tabular}
\end{center}
}
\caption{UW Vital Filtering scores at TRECKBA 2014\todo{need to fill it}}
\label{resMacro}
\end{table*}

We are surprised to see that {\textit{Embedding Combined}} outperformed all methods, achieving an F1 of 0.409. {\textit{Baseline Single} performs as expected, i.e. has lower F1 than the other models. On the other hand, {\textit{Baseline Multi-task}} perform far better that {\textit{Baseline Single}, which evidences that multi-task learning does work.

\def \officialRunWidth {0.23\textwidth}
\begin{figure}[tb]
  \centering
    \begin{subfigure}[b]{\officialRunWidth}
            \includegraphics[width=\textwidth]{fig/official/f_basic_single.png}
			\caption{Basic Single}
			\label{official:basic-single}
    \end{subfigure}
    ~
    \begin{subfigure}[b]{\officialRunWidth}
            \includegraphics[width=\textwidth]{fig/official/f_basic_multi.png}
			\caption{Basic Multi}
			\label{official:basic-single}
    \end{subfigure}
    ~
    \begin{subfigure}[b]{\officialRunWidth}
            \includegraphics[width=\textwidth]{fig/official/f_emb_comb.png}
			\caption{Emb Comb}
			\label{official:basic-single}
    \end{subfigure}
    ~
    \begin{subfigure}[b]{\officialRunWidth}
            \includegraphics[width=\textwidth]{fig/official/f_emb_pos.png}
			\caption{Emb POS}
			\label{official:basic-single}
    \end{subfigure}
    ~
    \begin{subfigure}[b]{\officialRunWidth}
            \includegraphics[width=\textwidth]{fig/official/f_mean_stat.png}
			\caption{Mean Stat}
			\label{official:basic-single}
    \end{subfigure}
    ~
    \begin{subfigure}[b]{\officialRunWidth}
            \includegraphics[width=\textwidth]{fig/official/f_mean_dyn.png}
			\caption{Mean Dyn}
			\label{official:basic-single}
    \end{subfigure}
    ~
    \begin{subfigure}[b]{\officialRunWidth}
            \includegraphics[width=\textwidth]{fig/official/f_clust_stat.png}
			\caption{Clust Stat}
			\label{official:basic-single}
    \end{subfigure}
    ~
    \begin{subfigure}[b]{\officialRunWidth}
            \includegraphics[width=\textwidth]{fig/official/f_clust_dyn.png}
			\caption{Clust Dyn}
			\label{official:basic-single}
    \end{subfigure}
\caption{P-R-F1-SU over confidence cutoffs}
\label{officialruns}
\end{figure}


\begin{figure}[tb]
\centering
\includegraphics[width=.5\textwidth]{fig/pr/overlapped.pdf}
\caption{Precision-Recall}
\label{precrecall}
\end{figure}

Most of the more advanced models perform better than {\textit{Baseline Multi-task}}. Using a combined embedding ({\textit{Embedding Combined}}) outperforms using individual embeddings representations for the different type of words ({\textit{Embedding POS}}).

Though the staleness and non-parametric clustering runs ({\textit{Mean Static}}, {\textit{Mean Dynamic}}, {\textit{Clustering Static}}, {\textit{Clustering Dynamic}}) perform slightly worse than the simple {\textit{Embedding Combined}} method, they illustrate the importance of these new features as they improve the performance of the {\textit{Embedding POS}} model.

Figure \ref{officialruns} complements the results in Table \ref{resMacro} for different confidence cutoffs. The metrics in each plot are nearly constant up to cutoff=500, and then decrease for higher cutoffs, which matches our expectations.

Figure \ref{precrecall} further illustrates the precision-recall for the different methods listed in Table \ref{resMacro}. It's worth noting that on low recall, the precision of the different models meets our expectations, the more complex methods, which include non-parametric clustering and staleness, outperform the simpler ones. Nevertheless, on high recall, {\textit{Embedding Combined}} takes the lead.

%Table \ref{varyinggamma} shows the results for a variant of {\textit{Clustering Dynamic}}. As opposed to the {\textit{Clustering Dynamic}} in Table \ref{res}, this new version uses a single embedding representation instead of embeddings per word type. We show outputs using a low, medium and high $\gamma_i$, for $\alpha=0.$. We further perform a scan on a long range of $\gamma_d$ to see its impact on the overall result. 

%\begin{table}[H]
%\center
%\begin{tabular}{|c|c|c|c|c|} \hline
%$\gamma_i$ & $\gamma_d$ & \textbf{P} & \textbf{R} & \textbf{F1} \\ \hline\hline
%0.1 & 0.2 & 0.525 & \textbf{0.518} & 0.521 \\ \hline
%0.1 & 0.5 & 0.537 & 0.514 & \textbf{0.525} \\ \hline
%0.1 & 1   & 0.516 & 0.514 & 0.515 \\ \hline
%0.1 & 20  & 0.512 & 0.506 & 0.509 \\ \hline
%0.1 & 100 & \textbf{0.583} & 0.463 & 0.516 \\ \hline\hline
%0.5 & 0.2 & \textbf{0.592*} & 0.479 & \textbf{0.530*} \\ \hline
%0.5 & 0.5 & 0.537 & 0.523 & 0.529 \\ \hline
%0.5 & 1   & 0.527 & 0.520 & 0.524 \\ \hline
%0.5 & 20  & 0.516 & 0.504 & 0.510 \\ \hline
%0.5 & 100 & 0.528 & \textbf{0.528} & 0.528 \\ \hline\hline
%0.9 & 0.2 & 0.529 & 0.509 & 0.519 \\ \hline
%0.9 & 0.5 & 0.533 & 0.520 & 0.526 \\ \hline
%0.9 & 1   & 0.540 & 0.518 & \textbf{0.529} \\ \hline
%0.9 & 20  & 0.521 & \textbf{0.529*} & 0.525 \\ \hline
%0.9 & 100 & \textbf{0.586} & 0.460 & 0.516 \\ \hline
%\end{tabular}
%\footnotetext{Footnote}
%\caption{Scores for variant of clustering dynamic with a single embedding and $\alpha=0.6$}
%\label{varyinggamma}
%\end{table}

%We achieve the best result when $\gamma_i=0.5$ and $\gamma_d=0.2$, still lower than \textit{Embedding Combined} but better than previous {\textit{Clustering Dynamic}}. In general, lower $\gamma_d$ seems to be doing a better job. These results further reflect the importance of hyperparameter tuning.

Figure \ref{varyingalpha} shows the results for a variant of {\textit{Clustering Dynamic}}. As opposed to the {\textit{Clustering Dynamic}} in Table \ref{resMacro}, this new version uses a single embedding representation instead of embeddings per word type. We show the change in micro P-R-F1 for different values of $\alpha$, using $\gamma_i=0.1$ and $\gamma_d=1$. We see that the performance degrades as $\alpha$ increases, which further reflects the importance of hyperparameter tuning.

\begin{figure}[tb]
\centering
\includegraphics[width=0.8\columnwidth]{fig/alphaPlotMacro.pdf}
\caption{P-R-F1 vs. $\alpha$}
\label{varyingalpha}
\end{figure}

Further, we present some qualitative results on the topic clusters of the previous method using $\alpha\mathord{=}0.8$. Table \ref{clusterresult} illustrates the 5 closest words to the word that is most similar (in cosine similarity) to the cluster centroids of Shawn Atleo on 11/15/2012.

\begin{table}[tb]
\center
\begin{tabular}{cc}
\toprule
\textbf{C1} & \textbf{C2} \\
\midrule
Monday & conduct \\ %\hline
Tuesday & complication \\ %\hline
month & judicial \\ %\hline
billion & government \\ %\hline
million & guidance \\
\bottomrule
\end{tabular}
\caption{Topic clusters closest words for ``Shawn Atleo''}
\label{clusterresult}
\end{table}

By doing some manual search on the entity Shawn Atleo, we can easily confirm that C2 elements make sense. Mr. Atleo is an activist for the rights of First Nations in Canada, and received several Honorary Doctorate of Laws degrees from different universities, which explains a cluster with the words in Table \ref{clusterresult}. C1 is somewhat harder, it is a cluster close to dates and maybe money. It may be explained by all the articles that talk about Shawn announcing huge investments in different areas.


We believe further experimental investigations are needed to account for the correct tunning of the hyperparameters of the model. Exploiting external resources such as Wikipedia entity pages to construct more features \cite{xitong12} should probably increase the overall accuracy of our method. It would also be interesting to assess the effects of using different pre-trained word embeddings.

\section{Conclusion \& Future Work}
\label{conclusion}

Filtering streaming documents to accelerate users filling knowledge gaps plays a crucial role in the maintenance and update of knowledge bases.
With the exponential increase of information on the web, it becomes critical to detect relevant documents and incorporate their information to entities in a timely manner \cite{jingang13}.

In this paper we introduce a semi-supervised learning model for document filtering tasks. We propose a distributed, non-parametric representation of documents suitable for streaming settings, that groups entities' references into topic clusters. Further, we present a notion of staleness computed per entity as well as per topic cluster, which dynamically estimates entities' and clusters' relevances.

Combining these three core ideas, distributed word embeddings, non-parametric clustering, and staleness, results in a more accurate representation of entities' contexts, and simultaneously addresses the filtering requirements of large corpora of streaming text documents.

Further work needs to be done. A possible line of future research would be exploring hierarchical clustering algorithms to better represent topic clusters. It would also be interesting to assess the effect of learning the hyperparameters of the model instead of just manual tuning them for the specific datasets.

%\clearpage
\section*{Acknowledgments} 
 
This work was supported in part by the Argentine Ministry of Science, Technology and Productive Innovation and the TerraSwarm Research Center, supported by the STARnet phase of the Focus Center Research Program (FCRP). Any opinions, findings and conclusions or recommendations expressed in this material are those of the authors and do not necessarily reflect those of the sponsors.

\small
\bibliography{../kba}
\bibliographystyle{icml2014}

\end{document} 


